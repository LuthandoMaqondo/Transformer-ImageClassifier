{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3701f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All major imports added.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U tensorflow-addons\n",
    "# !pip install tensorflow-addons\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "print(\"All major imports added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0a8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100     # Number of different classes of images that we'll be looking for.\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac68de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will result in 144 patches per image of 72x72 divided into patches of 6x6.\n",
      "Each image will be encoded into 144 vectors that are 64 long.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8 #The number of transformer blocks that we will stack together for deep learning.\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n",
    "print(f\"This will result in {num_patches} patches per image of {image_size}x{image_size} divided into patches of {patch_size}x{patch_size}.\");\n",
    "print(f\"Each image will be encoded into {num_patches} vectors that are {projection_dim} long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ab10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Normalization(),\n",
    "        tf.keras.layers.Resizing(image_size, image_size),\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(factor=0.02),\n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560af468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e732d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806d9801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image size: 32 X 32\n",
      "Resized Image size: 72 X 72\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 144\n",
      "Elements per patch: 108\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 144 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "# image = imgs\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Original Image size: {image.shape[0]} X {image.shape[1]}\")\n",
    "print(f\"Resized Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0dca63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371b6fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Shape of Encoded Patches:  (None, 144, 64)\n",
      "Encoded Patches:  KerasTensor(type_spec=TensorSpec(shape=(None, 144, 64), dtype=tf.float32, name=None), name='patch_encoder/add:0', description=\"created by layer 'patch_encoder'\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "# Augment data. (This will do the image preparation such as resizing it.)\n",
    "augmented = data_augmentation(inputs) \n",
    "# Create patches.\n",
    "patches = Patches(patch_size)(augmented)\n",
    "# Encode patches.\n",
    "encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "print(f\"Shape of Encoded Patches:  {encoded_patches.shape}\")\n",
    "print(f\"Encoded Patches:  {encoded_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e40777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(shape_of_input_images, num_target_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=shape_of_input_images)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.Flatten()(representation)\n",
    "    representation = tf.keras.layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = tf.keras.layers.Dense(num_target_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e597a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile, train, and evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "300154c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a63245c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " data_augmentation (Sequential)  (None, 72, 72, 3)   7           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " patches_2 (Patches)            (None, None, 108)    0           ['data_augmentation[1][0]']      \n",
      "                                                                                                  \n",
      " patch_encoder_1 (PatchEncoder)  (None, 144, 64)     16192       ['patches_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 144, 64)     128         ['patch_encoder_1[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 144, 64)     66368       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 144, 64)      0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder_1[0][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 144, 64)     128         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 144, 128)     8320        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 144, 128)     0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 144, 64)      8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 144, 64)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 144, 64)      0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 144, 64)     128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 144, 64)     66368       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 144, 64)      0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 144, 64)     128         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 144, 128)     8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 144, 128)     0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 144, 64)      8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 144, 64)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 144, 64)      0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 144, 64)     128         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 144, 64)     66368       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 144, 64)      0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_5 (LayerNo  (None, 144, 64)     128         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 144, 128)     8320        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 144, 128)     0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 144, 64)      8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 144, 64)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 144, 64)      0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 144, 64)     128         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 144, 64)     66368       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 144, 64)      0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 144, 64)     128         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 144, 128)     8320        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 144, 128)     0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 144, 64)      8256        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 144, 64)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 144, 64)      0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 144, 64)     128         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 144, 64)     66368       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 144, 64)      0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 144, 64)     128         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 144, 128)     8320        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 144, 128)     0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 144, 64)      8256        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 144, 64)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 144, 64)      0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 144, 64)     128         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 144, 64)     66368       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 144, 64)      0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 144, 64)     128         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 144, 128)     8320        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 144, 128)     0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 144, 64)      8256        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 144, 64)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 144, 64)      0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_12 (LayerN  (None, 144, 64)     128         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 144, 64)     66368       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 144, 64)      0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 144, 64)     128         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 144, 128)     8320        ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 144, 128)     0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 144, 64)      8256        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 144, 64)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 144, 64)      0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 144, 64)     128         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 144, 64)     66368       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 144, 64)      0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 144, 64)     128         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 144, 128)     8320        ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 144, 128)     0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 144, 64)      8256        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 144, 64)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 144, 64)      0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 144, 64)     128         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 9216)         0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 9216)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 2048)         18876416    ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 2048)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1024)         2098176     ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1024)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 100)          102500      ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,759,019\n",
      "Trainable params: 21,759,012\n",
      "Non-trainable params: 7\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_classifier = create_vit_classifier(input_shape, num_classes)\n",
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0247c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    history = run_experiment(vit_classifier)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fe052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
